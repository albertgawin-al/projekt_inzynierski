{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1V9YO88pRss"
      },
      "source": [
        "# Biblioteki"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8mhh6ZdRoSRm"
      },
      "outputs": [],
      "source": [
        "import multiprocessing, spacy, os, random\n",
        "import pandas as pd\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from IPython.display import clear_output\n",
        "from itertools import product\n",
        "from tqdm import tqdm\n",
        "\n",
        "cores = multiprocessing.cpu_count()\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Czyste dane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getCleanData():\n",
        "    clean_paths = os.listdir('new_clean_data')\n",
        "    clean_data = pd.DataFrame()\n",
        "\n",
        "    for path in tqdm(clean_paths, desc='Reading Data'):\n",
        "        clean_articles = pd.read_csv(f'new_clean_data/{path}', sep=',')\n",
        "        clean_data = pd.concat([clean_data, clean_articles], ignore_index=True)\n",
        "\n",
        "    return clean_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmzkxbG_V1b2"
      },
      "source": [
        "# Oznaczone dokumenty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pMlIbJ4sV4Pk"
      },
      "outputs": [],
      "source": [
        "def getTaggedDocuments(clean_data):\n",
        "    tqdm.pandas(desc=\"Tagging documents\")\n",
        "\n",
        "    def process_article(article):\n",
        "        \n",
        "        return TaggedDocument(str(article[\"clean_abstract\"]).split(), tags=[str(article[\"pmid\"])])\n",
        "\n",
        "    documents = clean_data.progress_apply(process_article, axis=1)\n",
        "\n",
        "    return documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reading Data: 100%|██████████| 1166/1166 [00:19<00:00, 61.26it/s]\n",
            "Tagging documents: 100%|██████████| 552462/552462 [00:14<00:00, 37364.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building vocabulary...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 553/553 [3:04:15<00:00, 19.99s/it]  \n"
          ]
        }
      ],
      "source": [
        "clean_data = getCleanData()\n",
        "documents = getTaggedDocuments(clean_data)\n",
        "\n",
        "vector_size_list = [200, 300]\n",
        "min_count_list = [20, 25]\n",
        "window_list = [10, 12]\n",
        "sample_list = [5e-5, 1e-4]\n",
        "alpha_list = [0.03, 0.035]\n",
        "min_alpha_list = [0.00001, 0.000001]\n",
        "\n",
        "model = Doc2Vec(vector_size=200, min_count=20, window=4, sample=1e-4,\n",
        "                alpha=0.03, min_alpha=0.00001, workers=cores-1)\n",
        "\n",
        "print(\"Building vocabulary...\")\n",
        "model.build_vocab(documents)\n",
        "\n",
        "batch_size = 1000\n",
        "num_batches = len(documents) // batch_size + 1\n",
        "\n",
        "for i in tqdm(range(num_batches), desc='Training'):\n",
        "    batch = documents[i*batch_size:(i+1)*batch_size]\n",
        "    model.train(batch, total_examples=len(batch), epochs=80)\n",
        "\n",
        "model.save(f\"models/main80.model\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
